# -*- coding: utf-8 -*-
"""
Created on Tue Feb  2 18:57:40 2021

@author: kubra
"""

# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dyDz_N4l24cYi1QuSJWuSoUB50vo1IMK
"""
import cv2
import numpy as np
from matplotlib import pyplot as plt
plt.style.use('ggplot')
import sys
sys.path.append('../common/')
import os
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from skimage import feature
from matplotlib import pyplot as plt
from sklearn.model_selection import KFold
from sklearn.metrics import classification_report

train_path = 'D:/proje/ICIAR2018_BACH_Challenge/patch256_thresh110_son/'

output_folder = "output"
#bins for colour histogram
bins = 32
random_seed = 9 

def mrange(start, step, end):
    """mimic behavior of MATLAB's range function
    """
    def gen(start, step, end):
        n = start
        while n <= end:
            yield n
            n = n+step
    return list(gen(start, step, end))


def findBorders(Im):
    I = np.pad(Im, [[1, 1], [1, 1]], 'constant', constant_values=1).astype('uint8')

    I2 = I[2:, 1:-1]+I[0:-2, 1:-1]+I[1:-1:, 2:]+I[1:-1:, 0:-2] + \
        I[2:, 2:]+I[2:, 0:-2]+I[0:-2, 2:]+I[0:-2, 0:-2]
    return Im * (I2 < 8)


def otsu(counts):
    p = counts*1.0/np.sum(counts)
    omega = np.cumsum(p)
    mu = np.cumsum(p*range(1, len(p)+1))
    mu_t = mu[-1]

    sigma_b_squared = (mu_t * omega - mu)**2 / (omega * (1-omega))
    maxval = np.max(np.nan_to_num(sigma_b_squared))
    if np.isnan(sigma_b_squared).all():
        pos = 0
    else:
        pos = np.mean((sigma_b_squared == maxval).nonzero())+1
    return pos


def otsurec(I, ttotal):
    if I == []:
        T = []
    else:
        I = I.astype(np.uint8).flatten()

        num_bins = 256
        counts = np.histogram(I, range(num_bins))[0]

        T = np.zeros((ttotal, 1))

        def otsurec_helper(lowerBin, upperBin, tLower, tUpper):
            if ((tUpper < tLower) or (lowerBin >= upperBin)):
                return
            level = otsu(counts[int(np.ceil(lowerBin))-1:int(np.ceil(upperBin))]) + lowerBin

            insertPos = int(np.ceil((tLower + tUpper) / 2.))
            T[insertPos-1] = level / num_bins
            otsurec_helper(lowerBin, level, tLower, insertPos - 1)
            otsurec_helper(level + 1, upperBin, insertPos + 1, tUpper)

        otsurec_helper(1, num_bins, 1, ttotal)
    return [t[0] for t in T]


def hausDim(I):
    maxDim = np.max(np.shape(I))
    newDimSize = int(2**np.ceil(np.log2(maxDim)))
    rowPad = newDimSize - np.shape(I)[0]
    colPad = newDimSize - np.shape(I)[1]

    I = np.pad(I, ((0, rowPad), (0, colPad)), 'constant')

    boxCounts = np.zeros(int(np.ceil(np.log2(maxDim)))+1)
    resolutions = np.zeros(int(np.ceil(np.log2(maxDim)))+1)

    iSize = np.shape(I)[0]
    boxSize = 1
    idx = 0
    while boxSize <= iSize:
        boxCount = (I > 0).sum()
        idx = idx + 1
        boxCounts[idx-1] = boxCount
        resolutions[idx-1] = 1./boxSize

        boxSize = boxSize*2
        I = I[::2, ::2]+I[1::2, ::2]+I[1::2, 1::2]+I[::2, 1::2]
    D = np.polyfit(np.log(resolutions), np.log(boxCounts), 1)
    return D[0]


def sfta(I, nt):
    if len(np.shape(I)) == 3:
        I = np.mean(I, 2)
    elif len(np.shape(I)) != 2:
        raise ImageDimensionError

    I = I.astype(np.uint8)

    T = otsurec(I, nt)
    dSize = len(T)*6
    D = np.zeros(dSize)
    pos = 0
    for t in range(len(T)):
        thresh = T[t]
        Ib = I > (thresh*255)
        Ib = findBorders(Ib)

        vals = I[Ib.nonzero()].astype(np.double)
        D[pos] = hausDim(Ib)
        pos += 1

        D[pos] = np.mean(vals)
        pos += 1

        D[pos] = len(vals)
        pos += 1

    T = T+[1.0, ]
    for t in range(len(T)-1):
        lowerThresh = T[t]
        upperThresh = T[t+1]
        Ib = (I > (lowerThresh*255)) * (I < (upperThresh*255))
        Ib = findBorders(Ib)

        vals = I[Ib.nonzero()].astype(np.double)
        D[pos] = hausDim(Ib)
        pos += 1

        D[pos] = np.mean(vals)
        pos += 1

        D[pos] = len(vals)
        pos += 1
    return D

def sfta_feature(image):
    gray= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
    th = 4       #threshold
    sonuc = sfta(gray, th)
    return sonuc

labels = []
features = []
hog_images=[]

# filter all the warnings
import warnings
warnings.filterwarnings('ignore')

train_labels = os.listdir(train_path)
train_labels.sort()


# Iterate over the training images:
for typefile in train_labels:
    lesiontype = os.listdir(os.path.join(train_path,typefile))
    current_label = typefile
    for filename in lesiontype:   
        imgpath = os.path.join(train_path,typefile,filename)
        image = cv2.imread(imgpath)
        print(imgpath)
        feature = sfta_feature(image)
        labels.append(current_label)
        features.append(feature)
        #hog_images.append(hog_img)
        

    

print ("[STATUS] completed Global Feature Extraction...")
print ("[STATUS] feature vector size {}".format(np.array(features).shape))
print ("[STATUS] training Labels {}".format(np.array(labels).shape))

print("one feature example:\n")
print(features[1])
print("\n")
len(features),len(labels)

print ("[STATUS] completed Global Feature Extraction...")

# get the overall feature vector size
print ("[STATUS] feature vector size {}".format(np.array(features).shape))

# get the overall training label size
print ("[STATUS] training Labels {}".format(np.array(labels).shape))

targetNames = np.unique(labels)
le = LabelEncoder()
target = le.fit_transform(labels)
print ("[STATUS] training labels encoded...")

# normalize the feature vector in the range (0-1)
scaler = MinMaxScaler(feature_range=(0, 1))
rescaled_features = scaler.fit_transform(features)
print ("[STATUS] feature vector normalized...")

print ("[STATUS] target labels: {}".format(target))
print( "[STATUS] target labels shape: {}".format(target.shape))

rescaled_features= np.nan_to_num(rescaled_features,0)


models = []
models.append(('KNN', KNeighborsClassifier(n_neighbors=7)))
models.append(('RF', RandomForestClassifier(n_estimators=700, random_state=9)))
models.append(('SVM', SVC(C=200,gamma=2)))

results = []
names = []
scoring = "accuracy"

(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(rescaled_features),
                                                                                          np.array(target),
                                                                                          test_size=0.2,
                                                                                          random_state=9)
print("\n")
print("************************************************************")
print("K-Fold Results")
print("************************************************************")
print("\n")

for name, model in models:
    kfold = KFold(n_splits=5, random_state=9)
    cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)
    print(cross_val_score(model, trainDataGlobal,trainLabelsGlobal, cv=kfold, scoring=scoring))
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)
    
    
print("\n") 
print("************************************************************")
print("************************************************************")
print("\n")

from sklearn import metrics
for name, model in models:
    clf=model
    clf.fit(trainDataGlobal, trainLabelsGlobal)
    y_pred=clf.predict(testDataGlobal)
    msg = "%s: %f " % (name, metrics.accuracy_score(y_pred,testLabelsGlobal))
    print(msg)
    
target_names = ['Benign', 'InSitu', 'Invasive', 'Normal']
print(classification_report(testLabelsGlobal, y_pred, target_names=target_names))

import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix

plot_confusion_matrix(clf, testDataGlobal, testLabelsGlobal)  
plt.show()  